<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>如何保证kafka消息不丢失 | sudo Cheers</title><meta name="author" content="ChiefX"><meta name="copyright" content="ChiefX"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="如何保证kafka消息不丢失我们从producer、consumer、broker三个角度进行分析。 消息传输保障一般而言，消息中间件的消息传输保障有 3 个层级 如下图所示：  Kafka的消息传输保障机制很直观。 针对生产者而言，生产者发送消息后： 若消息被成功提交到日志文件，因为多副本机制，那么这个消息就不会丢失； 若消息没有被成功提交到日志文件，如遭遇到了网络波动等问题，生产者无法判断消息">
<meta property="og:type" content="article">
<meta property="og:title" content="如何保证kafka消息不丢失">
<meta property="og:url" content="http://example.com/2025/06/15/%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81kafka%E6%B6%88%E6%81%AF%E4%B8%8D%E4%B8%A2%E5%A4%B1/index.html">
<meta property="og:site_name" content="sudo Cheers">
<meta property="og:description" content="如何保证kafka消息不丢失我们从producer、consumer、broker三个角度进行分析。 消息传输保障一般而言，消息中间件的消息传输保障有 3 个层级 如下图所示：  Kafka的消息传输保障机制很直观。 针对生产者而言，生产者发送消息后： 若消息被成功提交到日志文件，因为多副本机制，那么这个消息就不会丢失； 若消息没有被成功提交到日志文件，如遭遇到了网络波动等问题，生产者无法判断消息">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/image/head.png">
<meta property="article:published_time" content="2025-06-15T09:12:19.000Z">
<meta property="article:modified_time" content="2025-06-15T10:18:56.897Z">
<meta property="article:author" content="ChiefX">
<meta property="article:tag" content="中间件">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/image/head.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "如何保证kafka消息不丢失",
  "url": "http://example.com/2025/06/15/%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81kafka%E6%B6%88%E6%81%AF%E4%B8%8D%E4%B8%A2%E5%A4%B1/",
  "image": "http://example.com/image/head.png",
  "datePublished": "2025-06-15T09:12:19.000Z",
  "dateModified": "2025-06-15T10:18:56.897Z",
  "author": [
    {
      "@type": "Person",
      "name": "ChiefX",
      "url": "http://example.com/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2025/06/15/%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81kafka%E6%B6%88%E6%81%AF%E4%B8%8D%E4%B8%A2%E5%A4%B1/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '如何保证kafka消息不丢失',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="loading-box"><div class="cat__scene"><div class="cat__main"><div class="cat__body"></div><div class="cat__body"></div><div class="cat__tail"></div><div class="cat__head"></div></div></div></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/image/head.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">3</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">2</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/image/bak.webp);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><img class="site-icon" src="/image/icon_logo.png" alt="Logo"><span class="site-name">sudo Cheers</span></a><a class="nav-page-title" href="/"><span class="site-name">如何保证kafka消息不丢失</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">如何保证kafka消息不丢失</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-06-15T09:12:19.000Z" title="发表于 2025-06-15 17:12:19">2025-06-15</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-06-15T10:18:56.897Z" title="更新于 2025-06-15 18:18:56">2025-06-15</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/kafka%E7%9B%B8%E5%85%B3/">kafka相关</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 id="如何保证kafka消息不丢失"><a href="#如何保证kafka消息不丢失" class="headerlink" title="如何保证kafka消息不丢失"></a>如何保证kafka消息不丢失</h1><p>我们从<code>producer</code>、<code>consumer</code>、<code>broker</code>三个角度进行分析。</p>
<h2 id="消息传输保障"><a href="#消息传输保障" class="headerlink" title="消息传输保障"></a>消息传输保障</h2><p>一般而言，消息中间件的消息传输保障有 3 个层级 如下图所示：</p>
<p><img src="https://gitee.com/zhang_lai_yan/to-pic-go/raw/master/img/Kafka%E4%B8%A2%E5%A4%B1.png"></p>
<p>Kafka的消息传输保障机制很直观。</p>
<p>针对生产者而言，生产者发送消息后：</p>
<p>若消息被成功提交到日志文件，因为多副本机制，那么这个消息就不会丢失；</p>
<p>若消息没有被成功提交到日志文件，如遭遇到了网络波动等问题，生产者无法判断消息是否已经提交成功，此时生产者可以进行重试，这个过程可能造成消息的重复写入。</p>
<p>在这里kafka提供的消息传输保障为<code>at least once</code>。</p>
<p>针对消费者而言，消费者处理消息和提交消费位移的顺序很大程度上决定了消费者提供哪种消息传输保障。</p>
<p>若消费者拉取完消息后，应用逻辑先处理消息后提交消费位移，那么在消息处理之后且位移提交之前消费者宕机了，等它重新上线后，会从上一次位移提交的位置拉取，造成重复消费，此时对应<code>at least once</code>。</p>
<p>若消费者拉取完消息后，应用逻辑先提交消费位移后处理消息，那么在位移提交之后且消息处理完成之前消费者宕机了，等它重新上线后，会从已经提交的位移处拉取，造成消息丢失，此时对应<code>at most once</code>。</p>
<h2 id="Producer端"><a href="#Producer端" class="headerlink" title="Producer端"></a><code>Producer</code>端</h2><h3 id="消息的发送"><a href="#消息的发送" class="headerlink" title="消息的发送"></a>消息的发送</h3><p><code>kafkaProducer</code>的<code>send()</code>方法并非void类型，而是<code>Future&lt;RecordMetadata&gt;</code>类型，它有两个重载方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> Future&lt;RecordMetadata&gt; <span class="title function_">send</span><span class="params">(ProducerRecord&lt;K,V&gt; record)</span></span><br><span class="line"><span class="keyword">public</span> Future&lt;RecordMetadata&gt; <span class="title function_">send</span><span class="params">(ProducerRecord&lt;K,V&gt; record,Callback callback)</span></span><br></pre></td></tr></table></figure>

<p><code>send()</code>方法本身是异步的，<code>send()</code>方法返回的<code>Future</code>对象可以使调用方稍后获得<strong>发送的结果</strong>。</p>
<p><strong>同步发送</strong>的发送方式可以利用返回的<code>Future</code>对象实现，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">        producer.send(record).get();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>上述代码在执行<code>send()</code>方法之后直接链式调用了<code>get()</code>方法来<strong>阻塞等待kafka的响应</strong>，一直到消息发送成功，或者发生异常。如果有异常出现就得捕获异常然后交给外层逻辑处理。</p>
<p>另一种同步发送代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    Future&lt;RecordMetadata&gt; send = producer.send(record);</span><br><span class="line">    <span class="type">RecordMetadata</span> <span class="variable">recordMetadata</span> <span class="operator">=</span> send.get();</span><br><span class="line">    System.out.println(recordMetadata.topic()+recordMetadata.partition()+recordMetadata.offset());</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">    e.printStackTrace();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>从上述代码可知，我们可以获得一个<code>RecordMetadata</code>对象，它里面包含了<strong>消息的一些元数据</strong>，比如主题、分区、偏移量等。如果不需要这些数据则第一种方法更省事。</p>
<p>异步发送代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    producer.send(record, <span class="keyword">new</span> <span class="title class_">Callback</span>() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onCompletion</span><span class="params">(RecordMetadata recordMetadata, Exception e)</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (e != <span class="literal">null</span>) &#123;</span><br><span class="line">                <span class="comment">//可以进行消息重发、记录异常等</span></span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                System.out.println(recordMetadata.topic() + recordMetadata.partition() + recordMetadata.offset());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">    e.printStackTrace();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>由上述代码知：异步发送一般是在<code>send()</code>方法中指定一个<code>Callback</code>的回调函数，kafka在返回响应时调用该函数来实现异步的发送确认。</p>
<p>tips：对于同一个分区而言，如果两个消息中<code>record1</code>优先于<code>record2</code>发送，则kafka可以保证对应的<code>Callback1</code>优先于<code>Callback2</code>调用，<strong>即回调函数的调用也可以保证分区有序</strong>。</p>
<hr>
<h3 id="Producer解决方案"><a href="#Producer解决方案" class="headerlink" title="Producer解决方案"></a><code>Producer</code>解决方案</h3><p><code>KafkaProducer</code>中一般会有两种类型的异常：可重试的异常和不可重试的异常。例如因为网络波动而导致的异常就是可重试的异常。</p>
<p>针对可重试的异常，可以配置<code>retries</code>参数，<strong>该参数意为在规定的重试次数内自行恢复就不会抛出异常</strong>。默认值为0(推荐3)，配置方式如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">prop.put(ProducerConfig.RETRIES_CONFIG,<span class="number">3</span>)</span><br></pre></td></tr></table></figure>

<p><strong>注意：该配置项会影响到一些性能。比如会增加客户端对于异常的反馈时延。</strong></p>
<p>当将上述配置设置为大于0的值的时候（<strong>可能会造成消息重复</strong>），<strong>如何避免消息重复的情况？</strong></p>
<p>kafka从0.11.0.0版本开始引入了<strong>幂等</strong>和<strong>事务</strong>两个特性，以此来实现<strong>EOS（<code>exactly once mantics</code>，精确一次处理语义）</strong>，保证重新发送不会导致消息在日志出现重复。<code>Broker</code> 为<code>Producer</code>分配了一个ID（<code>producer id</code>，简称<code>PID</code>），并通过每条消息的序列号（<code>sequence number</code>）进行去重。<strong>事务用来保证多个分区写入操作的原子性。</strong></p>
<p><strong>其中启用幂等传递的方法配置</strong>：<code>enable.idempotence = true</code>。</p>
<p><strong>启用事务支持的方法配置</strong>：设置属性 <code>transcational.id = 自己定义</code>。</p>
<p>另外有一个配置项需要注意：**<code>max.in.flight.requests.per.connection</code>**配置意为：限制每个连接（也就是客户端与 Node 之间的连接）最多缓存的请求数，默认为5。<strong>这个配置大于1的时候会出现错序现象</strong>（<strong>Kafka保证同一个分区内消息是有序的</strong>）：</p>
<ul>
<li>如果第一批消息写入失败，而第二批消息写入成功，那么生产者会重新发送第一批的消息。如果成功发送，则将造成这两批消息的错序。</li>
<li>若需要保证消息的顺序，则建议将<code>max.in.flight.requests.per.connection</code>设置为1，而不是把<code>acks</code>设置为0，<strong>不过这样依然会影响吞吐量。</strong></li>
</ul>
<p>与此相关还有一个配置项，即<code>retry.backoff.ms</code>参数，该参数用来设定两次重试之间的时间间隔，防止生产者过早放弃重试。</p>
<p>这些参数配合使用可以让生产者更稳妥地进行重试。</p>
<p><code>KafkaProducer</code>发送消息后会进行<code>commit</code>（将消息写入日志），由于副本机制，则可以保证消息不丢失，至于多少副本收到这条消息生产者才会认为这条消息成功写入，<strong>可以由<code>acks</code>这个参数来指定（重点，它涉及到了消息的可靠性与吞吐量之间的权衡）</strong>。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">prop.put(ProducerConfig.ACKS_CONFIG,<span class="string">&quot;-1&quot;</span>);</span><br></pre></td></tr></table></figure>

<p><code>ack</code>有三种类型的值（字符串类型）：</p>
<ul>
<li><p><code>acks=1</code>。默认值为1，生产者发送消息之后，只要分区的leader副本成功写入则就会收到来自服务器端的成功响应。</p>
<ul>
<li>如果消息无法写入leader副本（leader副本崩溃、正在重新选举），那么生产者就会获得一个错误的响应。<strong>为了避免消息的丢失，生产者可以选择重发消息。至此，可能造成消息的重复生产，即<code>at least once</code></strong>。</li>
<li>如果消息写入<code>leader</code>副本并成功返回响应给生产者，但是在其他follower副本拉取之前<code>leader</code>副本崩溃，那么此时这个消息还是丢失了，因为新选举的<code>leader</code>副本中并没有这条消息。</li>
<li><code>acks</code>设置为1，是消息可靠性和吞吐量之间的这种方案。</li>
</ul>
</li>
<li><p><code>acks=0</code>。生产者发送消息之后不需要等待任何服务器端的相应。</p>
<ul>
<li>如果在消息从发送到写入kafka的过程中出现异常，导致Kafka没有接收这条消息，那么生产者也无法得知，消息也就丢失了。</li>
<li>这个设置可以使吞吐量达到最大。</li>
</ul>
</li>
<li><p><code>acks=-1</code>。生产者发送消息之后，需要等待ISR中所有的副本都成功写入消息之后才能收到来自服务器端的成功响应，<strong>这个配置可以达到最强的可靠性</strong>。</p>
<ul>
<li><p>如果在成功写入<code>leader</code>副本之后，与ISR中所有副本同步之前<code>leader</code>副本宕机了，则生产者会受到异常一次告知此次发送失败。</p>
</li>
<li><p>注意：<strong>这并不代表消息就一定可靠谱</strong>！因为ISR中可能只有<code>leader</code>副本，此时就退化成了<code>acks=1</code>的情况。</p>
<h4 id="那么什么时候会出现ISR中只有leader副本的情况呢？"><a href="#那么什么时候会出现ISR中只有leader副本的情况呢？" class="headerlink" title="那么什么时候会出现ISR中只有leader副本的情况呢？"></a>那么什么时候会出现ISR中只有<code>leader</code>副本的情况呢？</h4><p>当<code>leader</code>副本的消息流入速度很快，而<code>follower</code>副本的同步速度很慢，在某一个临界点时所有的<code>follower</code>副本都被剔除出了ISR集合。这时候<code>acks=-1</code>就会演变为<code>acks=1</code>的情景，这样就增大了<strong>消息丢失</strong>的风险。</p>
<h4 id="怎么处理这种情况？"><a href="#怎么处理这种情况？" class="headerlink" title="怎么处理这种情况？"></a>怎么处理这种情况？</h4><p>kafka（<code>Broker</code>端）提供了一个参数来应对这种情况：<code>min.insync.replicas</code>参数（默认为1），可以配合<code>acks=-1</code>来使用。<strong>这个参数指定了ISR集合中最小的副本数</strong>。如果不满足则会抛出异常。</p>
<p>一般来说需要配置<strong>副本数&gt;<code>min.insync.replicas</code></strong>。例如配置副本数为3，<code>min.insync.replicas</code>配置为2。需要注意的是：<strong>该参数在提升可用性的时候会从侧面影响到kafka的可用性</strong>。例如ISR中只有一个<code>leader</code>副本，不配置该参数还能用，配置了就不能写入了。</p>
<p>与此相关还有一个配置，即<code>unclean.leader.election.enable</code>，默认为<code>false</code>。意为：<strong>是否可以当<code>leader</code>下线的时候从非ISR集合中选举新的<code>leader</code></strong>。如果为<code>true</code>，则会导致消息的丢失，设置为<code>false</code>则会影响可用性。具体配置需要根据需求灵活选择。</p>
<h4 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h4></li>
<li><p><code>acks</code>&#x3D;-1，保证所有副本都成功写入消息之后才能收到服务器端的成功响应。</p>
</li>
<li><p><code>min.insync.replicas</code>&gt;1，保证不会出现ISR集合只有<code>leader</code>副本的情况。</p>
</li>
<li><p><code>retries</code>&gt;&#x3D;3，增加重试次数以保证消息的不丢失（<strong>可能造成消息重复</strong>）</p>
</li>
<li><p><code>retry.backoff.ms</code>根据场景设置，配合<code>retries</code>参数进行重试。</p>
</li>
<li><p><code>max.in.flight.requests.per.connection</code>&#x3D;1，保证分区内消息的顺序性。</p>
</li>
<li><p><code>enable.idempotence = true</code>：启用幂等传递的方法配置，防止重试造成消息重复发送。</p>
<hr>
</li>
</ul>
</li>
</ul>
<h2 id="Broker端"><a href="#Broker端" class="headerlink" title="Broker端"></a><code>Broker</code>端</h2><p><code>Kafka Broker </code>集群接收到数据后会将数据进行持久化存储到磁盘，消息都是先写入到页缓存，然后由操作系统负责具体的刷盘任务或者使用<code>fsync</code>强制刷盘，如果此时 Broker 宕机 ，且选举了一个落后 <code>leader</code>副本很多的<code>follower</code>副本成为新的<code>leader</code>副本，那么落后的消息数据就会丢失。</p>
<h3 id="如何解决？"><a href="#如何解决？" class="headerlink" title="如何解决？"></a>如何解决？</h3><p>同步刷盘（不建议）:</p>
<p>通过<code>log.flush.interval.message</code>、<code>log.flush.interval.ms</code> 等参数来控制。同步刷盘可以提高消息的可靠性，防止由于机器掉电等异常造成处于页缓存而没有及时写入磁盘的消息丢失。<strong>但是会严重影响性能。</strong></p>
<p>通过<strong>多副本的机制</strong>来保障（推荐）。具体配置如下：</p>
<ul>
<li><code>unclean.leader.election.enable</code>：设置为<code>false</code>，拒绝从ISR集合之外的副本中选举<code>leader</code>副本。这样的话就不用担心选举出来的副本消息落后原<code>leader</code>副本太多。</li>
<li><code>replication.factor</code>：设置大于等于3，这样当<code>leader</code>副本宕机之后才有<code>follower</code>副本选举成<code>leader</code>。</li>
<li><code>min.insync.replicas</code>：设置为大于1，指定ISR集合中最小的副本数，保证了ISR集合中不会只有<code>leader</code>副本的情况出现。注意：副本数&gt;min.insync.replicas。</li>
</ul>
<hr>
<h2 id="Consumer端"><a href="#Consumer端" class="headerlink" title="Consumer端"></a><code>Consumer</code>端</h2><p>针对<code>Consumer</code>端，有一个配置需要特别注意：<code>enable.auto.commit</code>。该配置默认为<code>true</code>，即开启自动位移提交功能，此方式非常简便，但是<strong>会造成重复消费和消费丢失的问题</strong>。</p>
<p>这个默认的自动提交是<strong>定期提交</strong>，由客户端参数<code>auto.commit.interval.ms</code>控制，默认5s，到时会将拉渠道的每个分区中最大的消息位移进行提交。</p>
<p>我们可以将其设置为<code>false</code>来执行手动提交。</p>
<p>如果因为应用解析消息的异常，可能导致一部分消息一直无法消费，这时候可以将这类消息暂存在死信队列，以免影响整体的消费进度。</p>
<p>当我们使用手动提交位移的时候会遇到两种情况：</p>
<ul>
<li><p><strong>先处理消息，再提交位移</strong>（推荐）</p>
<p>  如果在处理消息的时候宕机了，由于没有成功提交位移，等<code>Consumer</code>重启后会从上次的<code>offset</code>重新拉取消息。<strong>造成重复消费的问题，需要业务保证幂等性。</strong></p>
</li>
<li><p><strong>先提交位移，再处理消息</strong><br>  如果提交了位移，处理消息的时候宕机了，由于位移已经提交，当<code>Consumer</code>重启后会从已经提交的<code>offset</code>出开始消费，之前未处理完成的消息不会再被处理，对于这个<code>Consumer</code>而言消息已经丢失了。</p>
</li>
</ul>
<p>在此处有一个原则：<strong>如果消息没有被成功消费，则不能提交所对应的消费位移。</strong></p>
<p>手动提交可以细分为同步提交和异步提交，即<code>Consumer</code>的<code>commitSync()</code>和<code>commitAsync()</code>这两个方法。以下代码均先处理消息，后提交位移！</p>
<p>同步提交代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (IS_RUNNING.get())&#123;</span><br><span class="line">    ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">100</span>);</span><br><span class="line">    <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">        <span class="comment">//逻辑处理</span></span><br><span class="line">    &#125;</span><br><span class="line">    consumer.commitSync();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>consumer.commitSync()</code>会根据<code>poll()</code>拉取的最新位移来进行提交，只要不发生不可恢复的错误，它就会阻塞消费者线程直到位移提交完成，对于不可恢复的异常，则需要将其捕获并做针对性处理。</p>
<p>除此之外还可以按照分区的粒度划分提交位移的界限，具体代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">while</span> (IS_RUNNING.get()) &#123;</span><br><span class="line">        ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">100</span>);</span><br><span class="line">        <span class="keyword">for</span> (TopicPartition partition : records.partitions()) &#123;</span><br><span class="line">            List&lt;ConsumerRecord&lt;String, String&gt;&gt; partitionRecords = records.records(partition);</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : partitionRecords) &#123;</span><br><span class="line">                <span class="comment">//业务逻辑</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="type">long</span> <span class="variable">lastOffset</span> <span class="operator">=</span> partitionRecords.get(partitionRecords.size() - <span class="number">1</span>).offset();</span><br><span class="line">            consumer.commitSync(Collections.singletonMap(partition, <span class="keyword">new</span> <span class="title class_">OffsetAndMetadata</span>(lastOffset + <span class="number">1</span>)));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">    e.printStackTrace();</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    consumer.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>与<code>commitSync()</code>相反，异步提交的方式在执行的时候消费者线程不会被阻塞，可能在提交消费位移的结果还没返回之前就开始了新的拉取操作，具体代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (IS_RUNNING.get()) &#123;</span><br><span class="line">    ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">100</span>);</span><br><span class="line">    <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;topic:&quot;</span> + record.topic() + <span class="string">&quot;,offset:&quot;</span> + record.offset() + <span class="string">&quot;,value:&quot;</span> + record.value());</span><br><span class="line">    &#125;</span><br><span class="line">    consumer.commitAsync(<span class="keyword">new</span> <span class="title class_">OffsetCommitCallback</span>() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onComplete</span><span class="params">(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets, Exception e)</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (e != <span class="literal">null</span>)&#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">                logger.error(<span class="string">&quot;fail to commit offsets &#123;&#125;&quot;</span>,offsets);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>当位移提交完成后会回调<code>OffsetCommitCallback</code>的<code>onComplete()</code>方法。</p>
<h3 id="如果异步提交的时候失败了怎么办？"><a href="#如果异步提交的时候失败了怎么办？" class="headerlink" title="如果异步提交的时候失败了怎么办？"></a>如果异步提交的时候失败了怎么办？</h3><p>若提交失败后选择重试，那么则会<strong>造成重复消费</strong>的问题！（一般来说不需要重试，因为位移提交失败的情况很少见，进行重试会增加代码逻辑的复杂度）</p>
<p>例如：某一次提交位移为a，但是提交失败了，然后下一次又异步提交了位移a+b，这次成功了。如果使用重试机制，若前一次的异步提交的消费位移在重试的时候成功了，那么此时的消费位移也将变成a，如果此时再发生异常，那么消费者恢复之后就会从a开始消费。</p>
<p>怎么解决？</p>
<p>可以设置一个递增的序号来维护异步提交的顺序。每次提交之后就增加序号相对应的值。在提交失败之后检查所提交的位移与序号的值的大小，如果前者较小，则说明有更大的位移已经提交过，则不用进行重试。</p>
<p>如果在异步提交的情况下，消费者异常退出，则很可能导致消息重复消费的情况，因为这种情况下无法及时提交位移；如果消费者正常退出或者发再均衡，那么可以退出或者再均衡之前使用同步提交的方式做好把关。</p>
<h4 id="总结：-1"><a href="#总结：-1" class="headerlink" title="总结："></a>总结：</h4><p>为保证消息不丢失，开启配置<code>enable.auto.commit</code>为<code>false</code>，代码逻辑使用<strong>先处理消息，再提交位移</strong>的方式，针对<strong>消息重复消费问题，需要业务保证幂等性</strong>。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://example.com">ChiefX</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2025/06/15/%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81kafka%E6%B6%88%E6%81%AF%E4%B8%8D%E4%B8%A2%E5%A4%B1/">http://example.com/2025/06/15/%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81kafka%E6%B6%88%E6%81%AF%E4%B8%8D%E4%B8%A2%E5%A4%B1/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="http://example.com" target="_blank">sudo Cheers</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/">中间件</a></div><div class="post-share"><div class="social-share" data-image="/image/head.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related full-width" href="/2025/06/15/%E4%BA%91%E9%85%92%E9%A6%86%E6%90%AD%E5%BB%BA%EF%BC%88%E4%B8%AA%E4%BA%BA%E7%94%A8%EF%BC%89/" title="云酒馆搭建（个人用）"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">云酒馆搭建（个人用）</div></div><div class="info-2"><div class="info-item-1">云酒馆搭建（个人用）目标：通过腾讯轻量应用服务器搭建sillytavern并使用nginx进行反向代理，实现域名访问。配置及环境 腾讯轻量应用服务器2H2G 50G 峰值带宽 30Mbps  Ubuntu Server 22.04 LTS 64bit  nginx version: nginx&#x2F;1.18.0 (Ubuntu)  node v22.16.0  Chrome版本 137.0.7151.104（正式版本） （64 位）   详细步骤（简易搭建） 初步环境搭建：需准备git，node.js  拉取酒馆：  切换路径cd /usr/local/games/  sudo git clone https://github.com/SillyTavern/SillyTavern -b release  输出如下图：    进入SillyTavern目录执行start脚本安装相关依赖（建议赋权sudo chmod -R 777 SillyTavern/*），如图：输出如图：  修改配置文件sudo vim...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/06/05/%E5%A6%82%E4%BD%95%E9%81%BF%E5%85%8DKafka%E7%9A%84%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9/" title="如何避免Kafka的重复消费"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-06-05</div><div class="info-item-2">如何避免Kafka的重复消费</div></div><div class="info-2"><div class="info-item-1">...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/image/head.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">ChiefX</div><div class="author-info-description">闲得无聊搞一个sillyTavern问题站</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">3</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">2</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81kafka%E6%B6%88%E6%81%AF%E4%B8%8D%E4%B8%A2%E5%A4%B1"><span class="toc-number">1.</span> <span class="toc-text">如何保证kafka消息不丢失</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B6%88%E6%81%AF%E4%BC%A0%E8%BE%93%E4%BF%9D%E9%9A%9C"><span class="toc-number">1.1.</span> <span class="toc-text">消息传输保障</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Producer%E7%AB%AF"><span class="toc-number">1.2.</span> <span class="toc-text">Producer端</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E6%81%AF%E7%9A%84%E5%8F%91%E9%80%81"><span class="toc-number">1.2.1.</span> <span class="toc-text">消息的发送</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Producer%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"><span class="toc-number">1.2.2.</span> <span class="toc-text">Producer解决方案</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%82%A3%E4%B9%88%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E5%87%BA%E7%8E%B0ISR%E4%B8%AD%E5%8F%AA%E6%9C%89leader%E5%89%AF%E6%9C%AC%E7%9A%84%E6%83%85%E5%86%B5%E5%91%A2%EF%BC%9F"><span class="toc-number">1.2.2.1.</span> <span class="toc-text">那么什么时候会出现ISR中只有leader副本的情况呢？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%8E%E4%B9%88%E5%A4%84%E7%90%86%E8%BF%99%E7%A7%8D%E6%83%85%E5%86%B5%EF%BC%9F"><span class="toc-number">1.2.2.2.</span> <span class="toc-text">怎么处理这种情况？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%BB%E7%BB%93%EF%BC%9A"><span class="toc-number">1.2.2.3.</span> <span class="toc-text">总结：</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Broker%E7%AB%AF"><span class="toc-number">1.3.</span> <span class="toc-text">Broker端</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%EF%BC%9F"><span class="toc-number">1.3.1.</span> <span class="toc-text">如何解决？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Consumer%E7%AB%AF"><span class="toc-number">1.4.</span> <span class="toc-text">Consumer端</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E6%9E%9C%E5%BC%82%E6%AD%A5%E6%8F%90%E4%BA%A4%E7%9A%84%E6%97%B6%E5%80%99%E5%A4%B1%E8%B4%A5%E4%BA%86%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F"><span class="toc-number">1.4.1.</span> <span class="toc-text">如果异步提交的时候失败了怎么办？</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%BB%E7%BB%93%EF%BC%9A-1"><span class="toc-number">1.4.1.1.</span> <span class="toc-text">总结：</span></a></li></ol></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/06/15/%E4%BA%91%E9%85%92%E9%A6%86%E6%90%AD%E5%BB%BA%EF%BC%88%E4%B8%AA%E4%BA%BA%E7%94%A8%EF%BC%89/" title="云酒馆搭建（个人用）">云酒馆搭建（个人用）</a><time datetime="2025-06-15T09:12:19.000Z" title="发表于 2025-06-15 17:12:19">2025-06-15</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/06/15/%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81kafka%E6%B6%88%E6%81%AF%E4%B8%8D%E4%B8%A2%E5%A4%B1/" title="如何保证kafka消息不丢失">如何保证kafka消息不丢失</a><time datetime="2025-06-15T09:12:19.000Z" title="发表于 2025-06-15 17:12:19">2025-06-15</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/06/05/%E5%A6%82%E4%BD%95%E9%81%BF%E5%85%8DKafka%E7%9A%84%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9/" title="如何避免Kafka的重复消费">如何避免Kafka的重复消费</a><time datetime="2025-06-05T10:04:34.000Z" title="发表于 2025-06-05 18:04:34">2025-06-05</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By ChiefX</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.5</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script src="https://cdn.bootcss.com/jquery/3.4.1/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/gh/xiabo2/CDN@latest/fishes.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>